{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_D(n, feature):\n",
    "    info_D = 0\n",
    "    feature_counts = Counter(feature)\n",
    "    for val in feature_counts:\n",
    "        p_i = feature_counts[val]/n\n",
    "        info_D -= p_i*math.log(p_i, 2)\n",
    "    return info_D\n",
    "\n",
    "def get_gini_D(n, feature):\n",
    "    gini_D = 1\n",
    "    feature_counts = Counter(feature)\n",
    "    for val in feature_counts:\n",
    "        p_i = feature_counts[val]/n\n",
    "        gini_D -= math.pow(p_i, 2)\n",
    "    return gini_D\n",
    "\n",
    "def get_info_gains(n, df):\n",
    "    # Info(D) and Gini(D)\n",
    "    class_data = df[df.columns[-1]]\n",
    "    info_D = get_info_D(n, class_data)\n",
    "    gini_D = get_gini_D(n, class_data)\n",
    "    \n",
    "    # Info_class(D), Split_Info(D), and Gini_class(D)\n",
    "    feature_info_gain = []\n",
    "    feature_split_info = []\n",
    "    feature_gini_indicies = []\n",
    "    \n",
    "    # Loop over attributes\n",
    "    for i in range(len(df.columns)-1):\n",
    "        # Create summation bases\n",
    "        feature_info = 0\n",
    "        split_info = 0\n",
    "        feature_gini = 0\n",
    "        \n",
    "        # Group by subsections\n",
    "        col = df.groupby(df[df.columns[i]])[df.columns[-1]]\n",
    "        for key in col: # key[0] = key, key[1] = table of key vs class\n",
    "            # Extract number of elements in subsection\n",
    "            num_keys = len(key[1])\n",
    "            \n",
    "            # Calculate respective info\n",
    "            split_info -= num_keys/n * math.log(num_keys/n, 2)\n",
    "            feature_info += num_keys/n * (get_info_D(num_keys, key[1]))\n",
    "            feature_gini += num_keys/n * (get_gini_D(num_keys, key[1]))\n",
    "            \n",
    "        # Append into respective array index\n",
    "        feature_info_gain.append(feature_info)\n",
    "        feature_split_info.append(split_info)\n",
    "        feature_gini_indicies.append(feature_gini)\n",
    "        \n",
    "    # Gain(class), \n",
    "    Gain_D = [info_D - info_A_D for info_A_D in feature_info_gain]\n",
    "    delta_gini_D = [gini_D - gini_A_D for gini_A_D in feature_gini_indicies]\n",
    "    \n",
    "    # Return attribute info arrays\n",
    "    return Gain_D, feature_split_info, feature_gini_indicies\n",
    "\n",
    "def calc_gain_ratio(info_gains, split_info):\n",
    "    if len(info_gains) != len(split_info):\n",
    "        print(\"ERROR\")\n",
    "    else:\n",
    "        feature_gain_ratio = []\n",
    "        for i in range(len(info_gains)):\n",
    "            feature_gain_ratio.append(info_gains[i]/split_info[i])\n",
    "            \n",
    "    return feature_gain_ratio\n",
    "\n",
    "def tup_index_val_list(info):\n",
    "    info_tups = []\n",
    "    for e in range(len(info)):\n",
    "        tup = (e, info[e])\n",
    "        info_tups.append(tup)\n",
    "    return info_tups\n",
    "\n",
    "def output(df, info_gains, gain_ratios, gini_indicies):\n",
    "    print(\"Best splits\")\n",
    "    max_info_gain = info_gains.index(max(info_gains))\n",
    "    max_gain_ratio = gain_ratios.index(max(gain_ratios))\n",
    "    min_gini_index = gini_indicies.index(min(gini_indicies))\n",
    "    \n",
    "    print(df.columns[max_info_gain])\n",
    "    print(df.columns[max_gain_ratio])\n",
    "    print(df.columns[min_gini_index])\n",
    "    \n",
    "    print()\n",
    "    print(\"Worst Splits\")\n",
    "    min_info_gain = info_gains.index(min(info_gains))\n",
    "    min_gain_ratio = gain_ratios.index(min(gain_ratios))\n",
    "    max_gini_index = gini_indicies.index(max(gini_indicies))\n",
    "    \n",
    "    print(df.columns[min_info_gain])\n",
    "    print(df.columns[min_gain_ratio])\n",
    "    print(df.columns[max_gini_index])\n",
    "\n",
    "    print()\n",
    "    print(\"Sorted\")\n",
    "    info_gain_tups = tup_index_val_list(info_gains)\n",
    "    gain_ratio_tups = tup_index_val_list(gain_ratios)\n",
    "    gini_index_tups = tup_index_val_list(gini_indicies)\n",
    "    \n",
    "    info_gain_tups.sort(key=lambda tup: -tup[1])\n",
    "    gain_ratio_tups.sort(key=lambda tup: -tup[1])\n",
    "    gini_index_tups.sort(key=lambda tup: tup[1])\n",
    "    \n",
    "    print(\"Top 5\")\n",
    "    for i in range(5):\n",
    "        print()\n",
    "        print(df.columns[info_gain_tups[i][0]], info_gain_tups[i][1])\n",
    "        print(df.columns[gain_ratio_tups[i][0]], gain_ratio_tups[i][1])\n",
    "        print(df.columns[gini_index_tups[i][0]], gini_index_tups[i][1])\n",
    "    \n",
    "    print()\n",
    "    print(\"Bottom 5\")\n",
    "    for i in range(1, 6):\n",
    "        print()\n",
    "        print(df.columns[info_gain_tups[-i][0]], info_gain_tups[-i][1])\n",
    "        print(df.columns[gain_ratio_tups[-i][0]], gain_ratio_tups[-i][1])\n",
    "        print(df.columns[gini_index_tups[-i][0]], gini_index_tups[-i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainlib = pd.read_csv(\"training.csv\")\n",
    "testlib = pd.read_csv(\"testing.csv\")\n",
    "\n",
    "# Combine libraries for data processing\n",
    "all_data = trainlib.append(testlib)\n",
    "\n",
    "# New variables taken from previous kaggle competition\n",
    "all_data['Product_Info_2_char'] = all_data.Product_Info_2.str[0]\n",
    "all_data['Product_Info_2_num'] = all_data.Product_Info_2.str[1]\n",
    "all_data['Product_Info_2'] = pd.factorize(all_data['Product_Info_2'])[0]\n",
    "all_data['Product_Info_2_char'] = pd.factorize(all_data['Product_Info_2_char'])[0]\n",
    "all_data['Product_Info_2_num'] = pd.factorize(all_data['Product_Info_2_num'])[0]\n",
    "all_data['BMI_Age'] = all_data['BMI'] * all_data['Ins_Age']\n",
    "med_keyword_columns = all_data.columns[all_data.columns.str.startswith('Medical_Keyword_')]\n",
    "all_data['Med_Keywords_Count'] = all_data[med_keyword_columns].sum(axis=1)\n",
    "all_data.apply(lambda x: sum(x.isnull()),1)\n",
    "all_data['countna'] = all_data.apply(lambda x: sum(x.isnull()),1)\n",
    "all_data.fillna(-1, inplace=True)\n",
    "all_data['Response'] = all_data['Response'].astype(int)\n",
    "\n",
    "train_ohd = all_data[all_data['Response']>0].copy()\n",
    "test_ohd = all_data[all_data['Response']<1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set response column as last column in df\n",
    "cols = list(train_ohd.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('Response')) #Remove response from list\n",
    "train_ohd = train_ohd[cols+['Response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate out the response column\n",
    "target = train_ohd[\"Response\"]\n",
    "train_db = train_ohd.drop([\"Response\"], axis=1)\n",
    "test_db = test_ohd.drop([\"Response\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best splits\n",
      "Id\n",
      "Id\n",
      "Id\n",
      "\n",
      "Worst Splits\n",
      "Medical_Keyword_44\n",
      "Medical_Keyword_44\n",
      "Medical_Keyword_45\n",
      "\n",
      "Sorted\n",
      "Top 5\n",
      "\n",
      "Id 2.616780065604559\n",
      "Id 0.18314898817189662\n",
      "Id 0.0\n",
      "\n",
      "BMI_Age 2.0528668717869367\n",
      "BMI_Age 0.16090265225775663\n",
      "BMI_Age 0.22118787455003652\n",
      "\n",
      "BMI 0.7256017129926122\n",
      "Medical_History_32 0.139683306354558\n",
      "BMI 0.6424086001325987\n",
      "\n",
      "Medical_History_15 0.25908939965983446\n",
      "Medical_History_15 0.1196713313489524\n",
      "Wt 0.7412373890626542\n",
      "\n",
      "Wt 0.2580818055240641\n",
      "Medical_Keyword_15 0.10749323919147963\n",
      "Product_Info_4 0.7622367087289642\n",
      "\n",
      "Bottom 5\n",
      "\n",
      "Medical_Keyword_44 0.0002814021748429596\n",
      "Medical_Keyword_44 0.0008035558175679701\n",
      "Medical_Keyword_45 0.8072266433020672\n",
      "\n",
      "Medical_Keyword_45 0.00035586226958050915\n",
      "Medical_Keyword_45 0.0009186974884695719\n",
      "Medical_Keyword_44 0.8072168659545849\n",
      "\n",
      "Medical_Keyword_29 0.0005580852483113574\n",
      "Medical_History_36 0.0011773692867803418\n",
      "Medical_Keyword_6 0.8072015921526283\n",
      "\n",
      "Medical_Keyword_32 0.0006401854305648769\n",
      "Medical_History_26 0.0013117311465806825\n",
      "Medical_Keyword_41 0.8071952172552507\n",
      "\n",
      "Medical_Keyword_6 0.0006644957831061227\n",
      "Medical_Keyword_29 0.0015049064422321126\n",
      "Medical_Keyword_17 0.8071933306588289\n"
     ]
    }
   ],
   "source": [
    "info_gains, split_info, gini_indicies = get_info_gains(n, train_ohd)\n",
    "gain_ratios = calc_gain_ratio(info_gains, split_info)\n",
    "\n",
    "output(train_ohd, info_gains, gain_ratios, gini_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.36567285 6.08071657 7.22221344 ... 4.83641799 6.08147473 5.19269468]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(train_db, target)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "pred = regr.predict(test_db)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def specify(x1,x2,x3,x4,x5,x6,x7, arr):\n",
    "    '''\n",
    "    Digitize train list\n",
    "    '''\n",
    "    res = []\n",
    "    for y in arr:\n",
    "        if y < x1:\n",
    "            res.append(1)\n",
    "        elif y < x2:\n",
    "            res.append(2)\n",
    "        elif y < x3:\n",
    "            res.append(3)\n",
    "        elif y < x4:\n",
    "            res.append(4)\n",
    "        elif y < x5:\n",
    "            res.append(5)\n",
    "        elif y < x6:\n",
    "            res.append(6)\n",
    "        elif y < x7:\n",
    "            res.append(7)\n",
    "        else: res.append(8)\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Default cutoffs\n",
    "preds = specify(1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom cutoffs from previous kaggle submission\n",
    "preds = specify(1.5,2.9,3.1,4.5,5.5,6.1,7.1, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Id  Response\n",
      "0     20000         8\n",
      "1     20001         6\n",
      "2     20002         8\n",
      "3     20003         7\n",
      "4     20004         5\n",
      "5     20005         6\n",
      "6     20006         7\n",
      "7     20007         4\n",
      "8     20008         5\n",
      "9     20009         5\n",
      "10    20010         6\n",
      "11    20011         5\n",
      "12    20012         7\n",
      "13    20013         5\n",
      "14    20014         6\n",
      "15    20015         5\n",
      "16    20016         7\n",
      "17    20017         7\n",
      "18    20018         5\n",
      "19    20019         5\n",
      "20    20020         5\n",
      "21    20021         5\n",
      "22    20022         7\n",
      "23    20023         8\n",
      "24    20024         5\n",
      "25    20025         4\n",
      "26    20026         7\n",
      "27    20027         8\n",
      "28    20028         7\n",
      "29    20029         8\n",
      "...     ...       ...\n",
      "9970  29970         7\n",
      "9971  29971         7\n",
      "9972  29972         6\n",
      "9973  29973         8\n",
      "9974  29974         4\n",
      "9975  29975         5\n",
      "9976  29976         8\n",
      "9977  29977         6\n",
      "9978  29978         7\n",
      "9979  29979         8\n",
      "9980  29980         7\n",
      "9981  29981         7\n",
      "9982  29982         7\n",
      "9983  29983         7\n",
      "9984  29984         6\n",
      "9985  29985         6\n",
      "9986  29986         4\n",
      "9987  29987         7\n",
      "9988  29988         6\n",
      "9989  29989         5\n",
      "9990  29990         7\n",
      "9991  29991         5\n",
      "9992  29992         8\n",
      "9993  29993         8\n",
      "9994  29994         5\n",
      "9995  29995         7\n",
      "9996  29996         6\n",
      "9997  29997         5\n",
      "9998  29998         6\n",
      "9999  29999         5\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create submission csv\n",
    "res = pd.DataFrame()\n",
    "id_arr = [x for x in range(20000, len(preds)+20000)]\n",
    "res[\"Id\"] = id_arr\n",
    "res.set_index(\"Id\")\n",
    "res[\"Response\"] = preds\n",
    "res.to_csv(\"predictions.csv\", index=False)\n",
    "temp = pd.read_csv(\"predictions.csv\")\n",
    "print(temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
